{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "#np.asarray(prices)\n",
    "# Success\n",
    "print (\"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Boston housing dataset:\n",
      "\n",
      "Minimum price: $105,000.00\n",
      "Maximum price: $1,024,800.00\n",
      "Mean price: $454,342.94\n",
      "Median price $438,900.00\n",
      "Standard deviation of prices: $165,171.13\n"
     ]
    }
   ],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = min(prices)\n",
    "\n",
    "# TODO: Maximum price of the data\n",
    "maximum_price = max(prices)\n",
    "\n",
    "#  Mean price of the data\n",
    "mean_price =  np.mean(prices)\n",
    "\n",
    "#  Median price of the data\n",
    "median_price = np.median (prices)\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "# Show the calculated statistics\n",
    "print (\"Statistics for Boston housing dataset:\\n\")\n",
    "print (\"Minimum price: ${:,.2f}\".format(minimum_price))\n",
    "print (\"Maximum price: ${:,.2f}\".format(maximum_price))\n",
    "print (\"Mean price: ${:,.2f}\".format(mean_price))\n",
    "print (\"Median price ${:,.2f}\".format(median_price))\n",
    "print (\"Standard deviation of prices: ${:,.2f}\".format(std_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question 1 - Feature Observation\n",
    "As a reminder, we are using three features from the Boston housing dataset: 'RM', 'LSTAT', and 'PTRATIO'. For each data point (neighborhood):\n",
    "\n",
    "'RM' is the average number of rooms among homes in the neighborhood.\n",
    "'LSTAT' is the percentage of homeowners in the neighborhood considered \"lower class\" (working poor).\n",
    "'PTRATIO' is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n",
    "Using your intuition, for each of the three features above, do you think that an increase in the value of that feature would lead to an increase in the value of 'MEDV' or a decrease in the value of 'MEDV'? Justify your answer for each.\n",
    "\n",
    "Hint: This problem can phrased using examples like below.\n",
    "\n",
    "Would you expect a home that has an 'RM' value(number of rooms) of 6 be worth more or less than a home that has an 'RM' value of 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358830\n",
      "505704\n"
     ]
    }
   ],
   "source": [
    "#slicing prices acrroding to number of rooms\n",
    "# get the mean price of house if number of room < 6\n",
    "print(round(np.mean(prices [features['RM'] < 6])))\n",
    "# get the mean price of house if number of room > 6\n",
    "print(round(np.mean(prices [features['RM'] > 6])))\n",
    "# for values of RM increasing the prices increse also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357420\n",
      "293417\n",
      "402536\n",
      "577655\n",
      "910219\n"
     ]
    }
   ],
   "source": [
    "# Round RM values to make more sense \n",
    "# just for check\n",
    "RoundedRM=round(features['RM'])\n",
    "print(round(np.mean(prices [RoundedRM == 4])))\n",
    "print(round(np.mean(prices [RoundedRM == 5])))\n",
    "print(round(np.mean(prices [RoundedRM == 6])))\n",
    "print(round(np.mean(prices [RoundedRM == 7])))\n",
    "print(round(np.mean(prices [RoundedRM == 8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you expect a neighborhood that has an 'LSTAT' value(percent of lower class workers) of 15 have home prices be worth more or less than a neighborhood that has an 'LSTAT' value of 20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527325\n",
      "307028\n",
      "259918\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(prices [features['LSTAT'] < 15])))\n",
    "print(round(np.mean(prices [features['LSTAT'] > 15])))\n",
    "print(round(np.mean(prices [features['LSTAT'] > 20])))\n",
    "# for LSTAT values increasing the prices decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you expect a neighborhood that has an 'PTRATIO' value(ratio of students to teachers) of 10 have home prices be worth more or less than a neighborhood that has an 'PTRATIO' value of 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564471\n",
      "442079\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(prices [features['PTRATIO'] < 15])))\n",
    "print(round(np.mean(prices [features['PTRATIO'] > 15])))\n",
    "# for PTRATIO values increasing the prices decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 ansewer \n",
    "\n",
    " Feature Observation \n",
    "* an increase in the value of RM  feature would lead to an increase in the value of 'MEDV' .\n",
    "* an increase in the value of RM  feature would lead to an decrease in the value of 'MEDV' .\n",
    "* an increase in the value of RM  feature would lead to an decrease in the value of 'MEDV' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'r2_score' coefficient of determination R^2\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "# Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score =  r2_score(y_true, y_predict)\n",
    "# Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a coefficient of determination, R^2, of 0.923.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the performance of this model\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print (\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 answer \n",
    " this model to have successfully captured the variation of the target variable\n",
    " \n",
    "*** cause coefficient of determination (R^2) = .923 it means that 92.3% percent of the variance in Y_predict is predictable from \n",
    "the independent variables it close to 100% so it's a good prediction ratio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation: Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# Import 'train_test_split'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "#Split the data into 80% training and 20% testing.\n",
    "#Assign the train and testing splits to X_train, X_test, y_train, and y_test.\n",
    "# random_state=0 to ensure that  results are consistent\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices,train_size=.8, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Success\n",
    "print (\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 answer \n",
    " the benefit to splitting a dataset into some ratio of training and testing subsets for a learning algorithm :\n",
    " \n",
    " \n",
    "* to know how well my model doing and compare between algorthims.\n",
    "* to choose the best algorthim which achive the best accuracy based on testing and training sets.\n",
    "* trying to reduce training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Model Performance\n",
    "In this third section of the project, you'll take a look at several models' learning and testing performances on various subsets of training data. Additionally, you'll investigate one particular algorithm with an increasing 'max_depth' parameter on the full training set to observe how model complexity affects performance. Graphing your model's performance based on varying criteria can be beneficial in the analysis process, such as visualizing behavior that may not have been apparent from the results alone.\n",
    "\n",
    "Learning Curves\n",
    "The following code cell produces four graphs for a decision tree model with different maximum depths. Each graph visualizes the learning curves of the model for both training and testing as the size of the training set is increased. Note that the shaded region of a learning curve denotes the uncertainty of that curve (measured as the standard deviation). The model is scored on both the training and testing sets using R2, the coefficient of determination.\n",
    "\n",
    "Run the code cell below and use these graphs to answer the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'visuals' has no attribute 'ModelLearning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-191abc15bbd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Produce learning curves for varying training set sizes and maximum depths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'visuals' has no attribute 'ModelLearning'"
     ]
    }
   ],
   "source": [
    "# Produce learning curves for varying training set sizes and maximum depths\n",
    "vs.ModelLearning(features, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
